import re
import numpy as np
from sentence_transformers import SentenceTransformer
from transformers import AutoTokenizer
from sentence_transformers.util import cos_sim
from langdetect import detect
from groq import Groq
import os


model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
tokenizer = AutoTokenizer.from_pretrained("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")


def clean_text(text: str) -> str:
    text = text.lower()
    text = re.sub(r"\b(t√¥i l√†|t√¥i|i am|i'm)\b", " ", text, flags=re.IGNORECASE)
    text = re.sub(r"\S+@\S+\.\S+", " ", text)  # email
    text = re.sub(r"\+?\d[\d\s\-\(\)]{8,}", " ", text)  # phone
    text = re.sub(r"\b[A-Zƒê][a-z√†-·ªπ]+\b", " ", text)  # proper nouns (names)
    text = re.sub(r"\s+", " ", text).strip()
    return text


def chunk_text(text: str, max_tokens=512) -> list:
    tokens = tokenizer.tokenize(text)
    chunks = []
    for i in range(0, len(tokens), max_tokens):
        chunk_tokens = tokens[i:i+max_tokens]
        chunk = tokenizer.convert_tokens_to_string(chunk_tokens)
        chunks.append(chunk)
    return chunks


def get_text_embedding(text: str, chunk_size=512) -> np.ndarray:
    cleaned = clean_text(text)
    chunks = chunk_text(cleaned, max_tokens=chunk_size)
    if not chunks:
        return np.zeros(model.get_sentence_embedding_dimension())
    embeddings = model.encode(chunks)
    return np.mean(embeddings, axis=0)


def calculate_similarity(text1: str, text2: str) -> float:
    emb1 = get_text_embedding(text1)
    emb2 = get_text_embedding(text2)
    return cos_sim(emb1, emb2).item()


def make_cv_text(parsed_content: dict) -> str:
    parts = []
    for section in ['mo_ta_ban_than', 'kinh_nghiem_lam_viec', 'hoc_van', 'du_an']:
        value = parsed_content.get(section, [])
        if isinstance(value, list):
            parts.extend([str(item) for item in value])
        else:
            parts.append(str(value))
    parts.extend(parsed_content.get("ky_nang", []))
    return ' '.join(parts)

def detect_language(text: str) -> str:
    try:
        lang = detect(text)
        return 'vi' if lang.startswith('vi') else 'en'
    except:
        return 'en'

def build_reasoning_prompt(cv_text: str, jd_text: str, sim: dict, lang: str) -> str:
    def fmt(score):
        return f"{score:.4f}" if isinstance(score, (int, float)) else "N/A"

    if lang == "vi":
        prompt = f"""
B·∫°n l√† m·ªôt chuy√™n gia tuy·ªÉn d·ª•ng c√≥ ki·∫øn th·ª©c s√¢u r·ªông v·ªÅ ƒë√°nh gi√° h·ªì s∆° ·ª©ng vi√™n. D∆∞·ªõi ƒë√¢y l√† n·ªôi dung CV v√† m√¥ t·∫£ c√¥ng vi·ªác (JD), c√πng v·ªõi m·ªôt s·ªë ƒëi·ªÉm s·ªë th·ªÉ hi·ªán m·ª©c ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c ph·∫ßn ch√≠nh (K·ªπ nƒÉng, Kinh nghi·ªám, H·ªçc v·∫•n, T·ªïng th·ªÉ) ƒë∆∞·ª£c t√≠nh b·∫±ng c√¥ng th·ª©c cosine similarity.
ƒêi·ªÉm s·ªë t∆∞∆°ng ƒë·ªìng n√†y ch·ªâ ƒë·ªÉ tham kh·∫£o v√† kh√¥ng ph·∫£i l√† y·∫øu t·ªë quy·∫øt ƒë·ªãnh duy nh·∫•t trong vi·ªác ƒë√°nh gi√° ·ª©ng vi√™n. C√≥ th·ªÉ quy·∫øt ƒë·ªãnh d·ª±a tr√™n n·ªôi dung c·ª• th·ªÉ c·ªßa CV v√† JD. N√™n ƒë∆∞a ra d·∫´n ch·ª©ng c·ª• th·ªÉ t·ª´ n·ªôi dung CV v√† JD ƒë·ªÉ h·ªó tr·ª£ ƒë√°nh gi√°.
H√£y th·ª±c hi·ªán c√°c b∆∞·ªõc sau:
1. üîπ **ƒêi·ªÉm ph√π h·ª£p**: D·ª±a tr√™n n·ªôi dung CV v√† JD, h√£y n√™u r√µ ph·∫ßn n√†o ph√π h·ª£p v·ªõi nhau, ƒë·∫∑c bi·ªát l√† nh·ªØng ph·∫ßn c√≥ ƒëi·ªÉm s·ªë t∆∞∆°ng ƒë·ªìng cao.
2. ‚ö†Ô∏è **Thi·∫øu s√≥t**: (V·ªõi nh·ªØng ph·∫ßn c√≥ ƒëi·ªÉm s·ªë t∆∞∆°ng ƒë·ªìng th·∫•p) H√£y ch·ªâ ra c√°c th√¥ng tin thi·∫øu, ch∆∞a kh·ªõp ho·∫∑c ch∆∞a l√†m n·ªïi b·∫≠t trong CV.
3. ‚úÖ **ƒê·ªÅ xu·∫•t c·∫£i thi·ªán**: G·ª£i √Ω c√°c b·ªï sung ho·∫∑c ch·ªânh s·ª≠a c·ª• th·ªÉ m√† ·ª©ng vi√™n n√™n th·ª±c hi·ªán ƒë·ªÉ tƒÉng kh·∫£ nƒÉng ph√π h·ª£p.


ƒêi·ªÉm t∆∞∆°ng ƒë·ªìng cosine:
- T·ªïng th·ªÉ: {fmt(sim['overall'])}
- K·ªπ nƒÉng: {fmt(sim['skills'])}
- Kinh nghi·ªám: {fmt(sim['experience'])}
- H·ªçc v·∫•n: {fmt(sim['education'])}

=== CV ===
{cv_text}

=== M√¥ t·∫£ c√¥ng vi·ªác ===
{jd_text}

Ch√∫ √Ω: Tr·∫£ v·ªÅ d∆∞·ªõi d·∫°ng  markdown, s·ª≠ d·ª•ng c√°c ti√™u ƒë·ªÅ v√† danh s√°ch ƒë·ªÉ l√†m r√µ c√°c ph·∫ßn kh√°c nhau. Lu√¥n ph·∫£n h·ªìi ho√†n to√†n b·∫±ng ti·∫øng Vi·ªát m∆∞·ª£t m√†.
"""
    else:
        prompt = f"""You are a senior recruitment specialist with deep expertise in evaluating candidates. Below is a candidate's CV and a Job Description (JD), along with similarity scores (calculated using cosine similarity) that reflect alignment in key areas: skills, experience, education, and overall.
the similarity scores are for reference only and not the sole deciding factor in candidate evaluation. Decisions should be based on the specific content of the CV and JD, with concrete evidence from both to support the assessment.
Please perform the following analysis:
1. üîπ **Matching Points**: Identify which parts of the CV align well with the JD, especially those with high similarity scores.
2. ‚ö†Ô∏è **Gaps**: (For sections with low similarity) Specify what is missing or underrepresented in the CV.
3. ‚úÖ **Improvement Suggestions**: Provide specific recommendations for how the candidate can enhance their fit for the role.

Cosine Similarity Scores:
- Overall: {fmt(sim['overall'])}
- Skills: {fmt(sim['skills'])}
- Experience: {fmt(sim['experience'])}
- Education: {fmt(sim['education'])}

=== CV ===
{cv_text}

=== Job Description ===
{jd_text}

Note: Respond in markdown format with clear headings and lists. Always reply in English.
"""
    return prompt


def call_groq_reasoning(prompt: str) -> str:
    client = Groq(api_key=os.getenv("GROQ_API_KEY"))
    if detect_language(prompt) == "vi":
        lang = "vi"
    else:
        lang = "en"
    system_prompt = (
        "B·∫°n l√† m·ªôt chuy√™n gia tuy·ªÉn d·ª•ng c√≥ ki·∫øn th·ª©c s√¢u r·ªông v·ªÅ ƒë√°nh gi√° h·ªì s∆° ·ª©ng vi√™n. "
        "H√£y ph√¢n t√≠ch chi ti·∫øt m·ª©c ƒë·ªô ph√π h·ª£p gi·ªØa CV v√† JD, d·ª±a tr√™n ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng cosine v√† n·ªôi dung c·ª• th·ªÉ. "
        "Lu√¥n ph·∫£n h·ªìi b·∫±ng ti·∫øng Vi·ªát."
        if lang == "vi"
        else
        "You are a senior talent acquisition specialist with deep expertise in candidate evaluation. "
        "Analyze in detail the relevance between the CV and the Job Description, based on cosine similarity scores and content. "
        "Always respond in English."
    )
    chat_completion = client.chat.completions.create(
        model="llama3-8b-8192",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": prompt}
        ]
    )
    return chat_completion.choices[0].message.content
